# Лабораторная работа №2
## Отчет по лабораторной работе
### 1. Теоретическая база
Цель работы — научиться работать с предобученными моделями, использовать их эмбеддинги для создания новых моделей и решать задачу классификации текстов. В данной работе использована модель AudioClassifier, которая представляет собой простую нейронную сеть с двумя полносвязными слоями.

Модель AudioClassifier:

1. Входной слой (fc1):

- Полносвязный слой с размером входных данных `input_size`, где

**`input size = n_mels * target_length`**, 

где `n_mels` — _количество Mel-полос_,

`target_length` — _фиксированная длина Mel Spectrogram_.

- Размер выходных данных: 512.

- Активация: ReLU (_Rectified Linear Unit_) по формуле:

***ReLu(x) = max(0, x)***

- ReLu применяется к выходу первого полносвязного слоя (fc1).
- Она обнуляет все отрицательные значения и оставляет положительные без изменений.
- Это нелинейная функция, которая позволяет модели изучать сложные зависимости.

2. Выходной слой (fc2):

- Полносвязный слой с размером входных данных 512 и выходных данных `num_classes` (_количество классов для классификации_).

- Активация: отсутствует (используется для вывода сырых значений перед применением функции потерь).

### 2. Описание разработанной системы
Принцип работы системы:
Используется датасет с заголовками видео и их категориями.
Заголовки преобразуются в эмбеддинги с помощью модели BERT.
Эмбеддинги используются в качестве входных данных для нейронной сети.
Нейронная сеть обучается на тренировочной выборке и тестируется на тестовой выборке.
Оценка качества модели проводится с использованием метрики F1-score.
Архитектура:
Входные данные: текстовые заголовки видео.
Предобработка: токенизация заголовков, генерация эмбеддингов через BERT.
Модель: простая нейронная сеть с одним полносвязным слоем.
Функция потерь: CrossEntropyLoss.
Оптимизатор: Adam.
Инфраструктура: PyTorch, GPU (если доступен).
Алгоритм работы:
Загрузка данных: Датасет с заголовками видео и категориями загружается и фильтруется.
Генерация эмбеддингов: Используется токенизатор и предобученная модель BERT для извлечения эмбеддингов (векторное представление заголовков).
Обучение модели: Нейронная сеть обрабатывает эмбеддинги, минимизирует функцию потерь и обновляет веса.
Оценка: После обучения модель тестируется на отложенной выборке, вычисляется F1-score.
### 3. Результаты работы и тестирования системы
Пример выводов в процессе обучения:

Эпоха 1, Потери: 0.353399395942688
Эпоха 2, Потери: 0.08572502434253693
Эпоха 3, Потери: 0.3152550458908081
F1-Score: 0.0902
Основные результаты:
Использование эмбеддингов BERT позволяет эффективно извлекать семантические признаки текста.
Простая нейронная сеть на основе эмбеддингов показала неудовлетворительное качество на задаче классификации.
Метрика F1-score для тестовой выборки составила 0.0902, что указывает на малую точность классификации. Из чего можно сделать вывод, что у модели проблемы с переобучением. И нужно вводить большое количество эпох и уменьшить степень обучения.
4. Выводы по работе
Использование предобученных эмбеддингов BERT значительно упрощает решение задач классификации текстов, так как позволяет избежать обучения сложных моделей с нуля.
Простая архитектура нейронной сети способна достичь удовлетворительной точности при условии качественного представления входных данных.
Важную роль играет корректная предобработка текста (токенизация, обрезка длины и т.д.), так как она влияет на качество извлекаемых эмбеддингов.
PyTorch предоставляет удобные инструменты для построения и обучения моделей, включая поддержку GPU.
5. Использованные источники
Devlin J., Chang M.-W., Lee K., Toutanova K. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding [электронный ресурс]. – 2019. – Режим доступа: https://arxiv.org/abs/1810.04805.
Hugging Face Transformers Documentation [электронный ресурс]. – Режим доступа: https://huggingface.co/docs/transformers/index (дата обращения: 25.12.2024).
PyTorch Documentation [электронный ресурс]. – Режим доступа: https://pytorch.org/docs/stable/ (дата обращения: 25.12.2024).
sklearn.metrics Documentation [электронный ресурс]. – Режим доступа: https://scikit-learn.org/stable/modules/model_evaluation.html (дата обращения: 25.12.2024).
